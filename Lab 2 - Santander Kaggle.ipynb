{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Santander Customer Transaction Prediction (KAGGLE)\n",
    "\n",
    "Leer de que trata la competencia\n",
    "\n",
    "https://www.kaggle.com/c/santander-customer-transaction-prediction/overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bajada de Dataset\n",
    "La siguiente celda baja el dataset y lo guarda en la carpeta /data.\n",
    "\n",
    "Luego de ejecutarla debería tener los archivos train.csv y test.csv en esta carpeta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carpeta on dataset:\n",
    "https://drive.google.com/drive/folders/19scmxZ64fe7mIneDwG21eF_QLn-8-S8j?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si quiero habilitar mi google drive descomentar\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargar datos de train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/lab-2/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.6042</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.7222</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4666</td>\n",
       "      <td>4.7433</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>1.4214</td>\n",
       "      <td>23.0347</td>\n",
       "      <td>-1.2706</td>\n",
       "      <td>-2.9275</td>\n",
       "      <td>10.2922</td>\n",
       "      <td>17.9697</td>\n",
       "      <td>-8.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>0</td>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.4905</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>-0.1508</td>\n",
       "      <td>9.1942</td>\n",
       "      <td>13.2876</td>\n",
       "      <td>-1.5121</td>\n",
       "      <td>3.9267</td>\n",
       "      <td>9.5031</td>\n",
       "      <td>17.9974</td>\n",
       "      <td>-8.8104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_code  target    var_0   var_1    var_2   var_3    var_4   var_5   var_6  \\\n",
       "0  train_0       0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187   \n",
       "1  train_1       0  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208   \n",
       "2  train_2       0   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427   \n",
       "3  train_3       0  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428   \n",
       "4  train_4       0   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405   \n",
       "\n",
       "     var_7  ...  var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
       "0  18.6266  ...   4.4354   3.9642   3.1364   1.6910  18.5227  -2.3978   \n",
       "1  16.5338  ...   7.6421   7.7214   2.5837  10.9516  15.4305   2.0339   \n",
       "2  14.6155  ...   2.9057   9.7905   1.6704   1.6858  21.6042   3.1417   \n",
       "3  14.9250  ...   4.4666   4.7433   0.7178   1.4214  23.0347  -1.2706   \n",
       "4  19.2514  ...  -1.4905   9.5214  -0.1508   9.1942  13.2876  -1.5121   \n",
       "\n",
       "   var_196  var_197  var_198  var_199  \n",
       "0   7.8784   8.5635  12.7803  -1.0914  \n",
       "1   8.1267   8.7889  18.3560   1.9518  \n",
       "2  -6.5213   8.2675  14.7222   0.3965  \n",
       "3  -2.9275  10.2922  17.9697  -8.9996  \n",
       "4   3.9267   9.5031  17.9974  -8.8104  \n",
       "\n",
       "[5 rows x 202 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Importar datos de test y asignarlos a la variable df_test desde la carpeta data/\n",
    "df_test  = pd.read_csv('data/lab-2/test.csv')\n",
    "# Miramos las primeras 5 observaciones del dataset\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID_code', 'target', 'var_0', 'var_1', 'var_2', 'var_3', 'var_4',\n",
       "       'var_5', 'var_6', 'var_7',\n",
       "       ...\n",
       "       'var_190', 'var_191', 'var_192', 'var_193', 'var_194', 'var_195',\n",
       "       'var_196', 'var_197', 'var_198', 'var_199'],\n",
       "      dtype='object', length=202)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Cuantas features (covariables, variable explicativa, variable independiente, variables exógenas) hay (dimensión de las observaciones, regresoras)? \n",
    "El dataset contiene 200 features (var_0 a var_199).  \n",
    "#### Que columna contiene la salida (variable dependiente, variable endógena)? \n",
    "La salida se encuentra en la columna `target`\n",
    "#### Cuantas clases hay? \n",
    "Hay 2 clases, etiquetadas como 0 y 1\n",
    "#### Cuantas observaciones tiene train?\n",
    "El dataset de entrenamiento contiene 200,000 observaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.100490</td>\n",
       "      <td>10.679914</td>\n",
       "      <td>-1.627622</td>\n",
       "      <td>10.715192</td>\n",
       "      <td>6.796529</td>\n",
       "      <td>11.078333</td>\n",
       "      <td>-5.065317</td>\n",
       "      <td>5.408949</td>\n",
       "      <td>16.545850</td>\n",
       "      <td>0.284162</td>\n",
       "      <td>...</td>\n",
       "      <td>3.234440</td>\n",
       "      <td>7.438408</td>\n",
       "      <td>1.927839</td>\n",
       "      <td>3.331774</td>\n",
       "      <td>17.993784</td>\n",
       "      <td>-0.142088</td>\n",
       "      <td>2.303335</td>\n",
       "      <td>8.908158</td>\n",
       "      <td>15.870720</td>\n",
       "      <td>-3.326537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.300653</td>\n",
       "      <td>3.040051</td>\n",
       "      <td>4.050044</td>\n",
       "      <td>2.640894</td>\n",
       "      <td>2.043319</td>\n",
       "      <td>1.623150</td>\n",
       "      <td>7.863267</td>\n",
       "      <td>0.866607</td>\n",
       "      <td>3.418076</td>\n",
       "      <td>3.332634</td>\n",
       "      <td>...</td>\n",
       "      <td>4.559922</td>\n",
       "      <td>3.023272</td>\n",
       "      <td>1.478423</td>\n",
       "      <td>3.992030</td>\n",
       "      <td>3.135162</td>\n",
       "      <td>1.429372</td>\n",
       "      <td>5.454369</td>\n",
       "      <td>0.921625</td>\n",
       "      <td>3.010945</td>\n",
       "      <td>10.438015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.408400</td>\n",
       "      <td>-15.043400</td>\n",
       "      <td>2.117100</td>\n",
       "      <td>-0.040200</td>\n",
       "      <td>5.074800</td>\n",
       "      <td>-32.562600</td>\n",
       "      <td>2.347300</td>\n",
       "      <td>5.349700</td>\n",
       "      <td>-10.505500</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.093300</td>\n",
       "      <td>-2.691700</td>\n",
       "      <td>-3.814500</td>\n",
       "      <td>-11.783400</td>\n",
       "      <td>8.694400</td>\n",
       "      <td>-5.261000</td>\n",
       "      <td>-14.209600</td>\n",
       "      <td>5.960600</td>\n",
       "      <td>6.299300</td>\n",
       "      <td>-38.852800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.453850</td>\n",
       "      <td>-4.740025</td>\n",
       "      <td>8.722475</td>\n",
       "      <td>5.254075</td>\n",
       "      <td>9.883175</td>\n",
       "      <td>-11.200350</td>\n",
       "      <td>4.767700</td>\n",
       "      <td>13.943800</td>\n",
       "      <td>-2.317800</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058825</td>\n",
       "      <td>5.157400</td>\n",
       "      <td>0.889775</td>\n",
       "      <td>0.584600</td>\n",
       "      <td>15.629800</td>\n",
       "      <td>-1.170700</td>\n",
       "      <td>-1.946925</td>\n",
       "      <td>8.252800</td>\n",
       "      <td>13.829700</td>\n",
       "      <td>-11.208475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.524750</td>\n",
       "      <td>-1.608050</td>\n",
       "      <td>10.580000</td>\n",
       "      <td>6.825000</td>\n",
       "      <td>11.108250</td>\n",
       "      <td>-4.833150</td>\n",
       "      <td>5.385100</td>\n",
       "      <td>16.456800</td>\n",
       "      <td>0.393700</td>\n",
       "      <td>...</td>\n",
       "      <td>3.203600</td>\n",
       "      <td>7.347750</td>\n",
       "      <td>1.901300</td>\n",
       "      <td>3.396350</td>\n",
       "      <td>17.957950</td>\n",
       "      <td>-0.172700</td>\n",
       "      <td>2.408900</td>\n",
       "      <td>8.888200</td>\n",
       "      <td>15.934050</td>\n",
       "      <td>-2.819550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.758200</td>\n",
       "      <td>1.358625</td>\n",
       "      <td>12.516700</td>\n",
       "      <td>8.324100</td>\n",
       "      <td>12.261125</td>\n",
       "      <td>0.924800</td>\n",
       "      <td>6.003000</td>\n",
       "      <td>19.102900</td>\n",
       "      <td>2.937900</td>\n",
       "      <td>...</td>\n",
       "      <td>6.406200</td>\n",
       "      <td>9.512525</td>\n",
       "      <td>2.949500</td>\n",
       "      <td>6.205800</td>\n",
       "      <td>20.396525</td>\n",
       "      <td>0.829600</td>\n",
       "      <td>6.556725</td>\n",
       "      <td>9.593300</td>\n",
       "      <td>18.064725</td>\n",
       "      <td>4.836800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.315000</td>\n",
       "      <td>10.376800</td>\n",
       "      <td>19.353000</td>\n",
       "      <td>13.188300</td>\n",
       "      <td>16.671400</td>\n",
       "      <td>17.251600</td>\n",
       "      <td>8.447700</td>\n",
       "      <td>27.691800</td>\n",
       "      <td>10.151300</td>\n",
       "      <td>...</td>\n",
       "      <td>18.440900</td>\n",
       "      <td>16.716500</td>\n",
       "      <td>8.402400</td>\n",
       "      <td>18.281800</td>\n",
       "      <td>27.928800</td>\n",
       "      <td>4.272900</td>\n",
       "      <td>18.321500</td>\n",
       "      <td>12.000400</td>\n",
       "      <td>26.079100</td>\n",
       "      <td>28.500700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              target          var_0          var_1          var_2  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        0.100490      10.679914      -1.627622      10.715192   \n",
       "std         0.300653       3.040051       4.050044       2.640894   \n",
       "min         0.000000       0.408400     -15.043400       2.117100   \n",
       "25%         0.000000       8.453850      -4.740025       8.722475   \n",
       "50%         0.000000      10.524750      -1.608050      10.580000   \n",
       "75%         0.000000      12.758200       1.358625      12.516700   \n",
       "max         1.000000      20.315000      10.376800      19.353000   \n",
       "\n",
       "               var_3          var_4          var_5          var_6  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        6.796529      11.078333      -5.065317       5.408949   \n",
       "std         2.043319       1.623150       7.863267       0.866607   \n",
       "min        -0.040200       5.074800     -32.562600       2.347300   \n",
       "25%         5.254075       9.883175     -11.200350       4.767700   \n",
       "50%         6.825000      11.108250      -4.833150       5.385100   \n",
       "75%         8.324100      12.261125       0.924800       6.003000   \n",
       "max        13.188300      16.671400      17.251600       8.447700   \n",
       "\n",
       "               var_7          var_8  ...        var_190        var_191  \\\n",
       "count  200000.000000  200000.000000  ...  200000.000000  200000.000000   \n",
       "mean       16.545850       0.284162  ...       3.234440       7.438408   \n",
       "std         3.418076       3.332634  ...       4.559922       3.023272   \n",
       "min         5.349700     -10.505500  ...     -14.093300      -2.691700   \n",
       "25%        13.943800      -2.317800  ...      -0.058825       5.157400   \n",
       "50%        16.456800       0.393700  ...       3.203600       7.347750   \n",
       "75%        19.102900       2.937900  ...       6.406200       9.512525   \n",
       "max        27.691800      10.151300  ...      18.440900      16.716500   \n",
       "\n",
       "             var_192        var_193        var_194        var_195  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        1.927839       3.331774      17.993784      -0.142088   \n",
       "std         1.478423       3.992030       3.135162       1.429372   \n",
       "min        -3.814500     -11.783400       8.694400      -5.261000   \n",
       "25%         0.889775       0.584600      15.629800      -1.170700   \n",
       "50%         1.901300       3.396350      17.957950      -0.172700   \n",
       "75%         2.949500       6.205800      20.396525       0.829600   \n",
       "max         8.402400      18.281800      27.928800       4.272900   \n",
       "\n",
       "             var_196        var_197        var_198        var_199  \n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000  \n",
       "mean        2.303335       8.908158      15.870720      -3.326537  \n",
       "std         5.454369       0.921625       3.010945      10.438015  \n",
       "min       -14.209600       5.960600       6.299300     -38.852800  \n",
       "25%        -1.946925       8.252800      13.829700     -11.208475  \n",
       "50%         2.408900       8.888200      15.934050      -2.819550  \n",
       "75%         6.556725       9.593300      18.064725       4.836800  \n",
       "max        18.321500      12.000400      26.079100      28.500700  \n",
       "\n",
       "[8 rows x 201 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Inspeccionar test\n",
    "# Puede ejecutar los métodos que crea necesarios. Recomendamos describe, columns, shape, head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.658737</td>\n",
       "      <td>-1.624244</td>\n",
       "      <td>10.707452</td>\n",
       "      <td>6.788214</td>\n",
       "      <td>11.076399</td>\n",
       "      <td>-5.050558</td>\n",
       "      <td>5.415164</td>\n",
       "      <td>16.529143</td>\n",
       "      <td>0.277135</td>\n",
       "      <td>7.569407</td>\n",
       "      <td>...</td>\n",
       "      <td>3.189766</td>\n",
       "      <td>7.458269</td>\n",
       "      <td>1.925944</td>\n",
       "      <td>3.322016</td>\n",
       "      <td>17.996967</td>\n",
       "      <td>-0.133657</td>\n",
       "      <td>2.290899</td>\n",
       "      <td>8.912428</td>\n",
       "      <td>15.869184</td>\n",
       "      <td>-3.246342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.036716</td>\n",
       "      <td>4.040509</td>\n",
       "      <td>2.633888</td>\n",
       "      <td>2.052724</td>\n",
       "      <td>1.616456</td>\n",
       "      <td>7.869293</td>\n",
       "      <td>0.864686</td>\n",
       "      <td>3.424482</td>\n",
       "      <td>3.333375</td>\n",
       "      <td>1.231865</td>\n",
       "      <td>...</td>\n",
       "      <td>4.551239</td>\n",
       "      <td>3.025189</td>\n",
       "      <td>1.479966</td>\n",
       "      <td>3.995599</td>\n",
       "      <td>3.140652</td>\n",
       "      <td>1.429678</td>\n",
       "      <td>5.446346</td>\n",
       "      <td>0.920904</td>\n",
       "      <td>3.008717</td>\n",
       "      <td>10.398589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.188700</td>\n",
       "      <td>-15.043400</td>\n",
       "      <td>2.355200</td>\n",
       "      <td>-0.022400</td>\n",
       "      <td>5.484400</td>\n",
       "      <td>-27.767000</td>\n",
       "      <td>2.216400</td>\n",
       "      <td>5.713700</td>\n",
       "      <td>-9.956000</td>\n",
       "      <td>4.243300</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.093300</td>\n",
       "      <td>-2.407000</td>\n",
       "      <td>-3.340900</td>\n",
       "      <td>-11.413100</td>\n",
       "      <td>9.382800</td>\n",
       "      <td>-4.911900</td>\n",
       "      <td>-13.944200</td>\n",
       "      <td>6.169600</td>\n",
       "      <td>6.584000</td>\n",
       "      <td>-39.457800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.442975</td>\n",
       "      <td>-4.700125</td>\n",
       "      <td>8.735600</td>\n",
       "      <td>5.230500</td>\n",
       "      <td>9.891075</td>\n",
       "      <td>-11.201400</td>\n",
       "      <td>4.772600</td>\n",
       "      <td>13.933900</td>\n",
       "      <td>-2.303900</td>\n",
       "      <td>6.623800</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.095000</td>\n",
       "      <td>5.166500</td>\n",
       "      <td>0.882975</td>\n",
       "      <td>0.587600</td>\n",
       "      <td>15.634775</td>\n",
       "      <td>-1.160700</td>\n",
       "      <td>-1.948600</td>\n",
       "      <td>8.260075</td>\n",
       "      <td>13.847275</td>\n",
       "      <td>-11.124000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10.513800</td>\n",
       "      <td>-1.590500</td>\n",
       "      <td>10.560700</td>\n",
       "      <td>6.822350</td>\n",
       "      <td>11.099750</td>\n",
       "      <td>-4.834100</td>\n",
       "      <td>5.391600</td>\n",
       "      <td>16.422700</td>\n",
       "      <td>0.372000</td>\n",
       "      <td>7.632000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.162400</td>\n",
       "      <td>7.379000</td>\n",
       "      <td>1.892600</td>\n",
       "      <td>3.428500</td>\n",
       "      <td>17.977600</td>\n",
       "      <td>-0.162000</td>\n",
       "      <td>2.403600</td>\n",
       "      <td>8.892800</td>\n",
       "      <td>15.943400</td>\n",
       "      <td>-2.725950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12.739600</td>\n",
       "      <td>1.343400</td>\n",
       "      <td>12.495025</td>\n",
       "      <td>8.327600</td>\n",
       "      <td>12.253400</td>\n",
       "      <td>0.942575</td>\n",
       "      <td>6.005800</td>\n",
       "      <td>19.094550</td>\n",
       "      <td>2.930025</td>\n",
       "      <td>8.584825</td>\n",
       "      <td>...</td>\n",
       "      <td>6.336475</td>\n",
       "      <td>9.531100</td>\n",
       "      <td>2.956000</td>\n",
       "      <td>6.174200</td>\n",
       "      <td>20.391725</td>\n",
       "      <td>0.837900</td>\n",
       "      <td>6.519800</td>\n",
       "      <td>9.595900</td>\n",
       "      <td>18.045200</td>\n",
       "      <td>4.935400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>22.323400</td>\n",
       "      <td>9.385100</td>\n",
       "      <td>18.714100</td>\n",
       "      <td>13.142000</td>\n",
       "      <td>16.037100</td>\n",
       "      <td>17.253700</td>\n",
       "      <td>8.302500</td>\n",
       "      <td>28.292800</td>\n",
       "      <td>9.665500</td>\n",
       "      <td>11.003600</td>\n",
       "      <td>...</td>\n",
       "      <td>20.359000</td>\n",
       "      <td>16.716500</td>\n",
       "      <td>8.005000</td>\n",
       "      <td>17.632600</td>\n",
       "      <td>27.947800</td>\n",
       "      <td>4.545400</td>\n",
       "      <td>15.920700</td>\n",
       "      <td>12.275800</td>\n",
       "      <td>26.538400</td>\n",
       "      <td>27.907400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               var_0          var_1          var_2          var_3  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean       10.658737      -1.624244      10.707452       6.788214   \n",
       "std         3.036716       4.040509       2.633888       2.052724   \n",
       "min         0.188700     -15.043400       2.355200      -0.022400   \n",
       "25%         8.442975      -4.700125       8.735600       5.230500   \n",
       "50%        10.513800      -1.590500      10.560700       6.822350   \n",
       "75%        12.739600       1.343400      12.495025       8.327600   \n",
       "max        22.323400       9.385100      18.714100      13.142000   \n",
       "\n",
       "               var_4          var_5          var_6          var_7  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean       11.076399      -5.050558       5.415164      16.529143   \n",
       "std         1.616456       7.869293       0.864686       3.424482   \n",
       "min         5.484400     -27.767000       2.216400       5.713700   \n",
       "25%         9.891075     -11.201400       4.772600      13.933900   \n",
       "50%        11.099750      -4.834100       5.391600      16.422700   \n",
       "75%        12.253400       0.942575       6.005800      19.094550   \n",
       "max        16.037100      17.253700       8.302500      28.292800   \n",
       "\n",
       "               var_8          var_9  ...        var_190        var_191  \\\n",
       "count  200000.000000  200000.000000  ...  200000.000000  200000.000000   \n",
       "mean        0.277135       7.569407  ...       3.189766       7.458269   \n",
       "std         3.333375       1.231865  ...       4.551239       3.025189   \n",
       "min        -9.956000       4.243300  ...     -14.093300      -2.407000   \n",
       "25%        -2.303900       6.623800  ...      -0.095000       5.166500   \n",
       "50%         0.372000       7.632000  ...       3.162400       7.379000   \n",
       "75%         2.930025       8.584825  ...       6.336475       9.531100   \n",
       "max         9.665500      11.003600  ...      20.359000      16.716500   \n",
       "\n",
       "             var_192        var_193        var_194        var_195  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        1.925944       3.322016      17.996967      -0.133657   \n",
       "std         1.479966       3.995599       3.140652       1.429678   \n",
       "min        -3.340900     -11.413100       9.382800      -4.911900   \n",
       "25%         0.882975       0.587600      15.634775      -1.160700   \n",
       "50%         1.892600       3.428500      17.977600      -0.162000   \n",
       "75%         2.956000       6.174200      20.391725       0.837900   \n",
       "max         8.005000      17.632600      27.947800       4.545400   \n",
       "\n",
       "             var_196        var_197        var_198        var_199  \n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000  \n",
       "mean        2.290899       8.912428      15.869184      -3.246342  \n",
       "std         5.446346       0.920904       3.008717      10.398589  \n",
       "min       -13.944200       6.169600       6.584000     -39.457800  \n",
       "25%        -1.948600       8.260075      13.847275     -11.124000  \n",
       "50%         2.403600       8.892800      15.943400      -2.725950  \n",
       "75%         6.519800       9.595900      18.045200       4.935400  \n",
       "max        15.920700      12.275800      26.538400      27.907400  \n",
       "\n",
       "[8 rows x 200 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 201)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Que columna esta en los datos de train pero no en los de test?\n",
    "La columna `target`\n",
    "#### Cuantas observaciones de test hay?\n",
    "El dataset de test tiene la misma cantidad de observaciones que train, 200,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.89951\n",
       "1    0.10049\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.target.value_counts()/len(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dividir data en Train y Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_train = 160_000\n",
    "X_train = df_train.drop(columns=['ID_code', 'target']).values[:N_train]\n",
    "X_val = df_train.drop(columns=['ID_code', 'target']).values[N_train:]\n",
    "y_train = df_train['target'].values[:N_train]\n",
    "y_val = df_train['target'].values[N_train:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver='lbfgs', max_iter = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.51 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jvidela\\miniconda3\\envs\\diplo\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A que se debe el warning no termina de convergence?\n",
    "El modelo no termina de converger debido a que se alcanzó el número máximo de iteraciones (100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.91204375\n",
      "0.85029461143855\n"
     ]
    }
   ],
   "source": [
    "acc = model.score(X_train, y_train)\n",
    "auc = roc_auc_score(y_train, model.predict_proba(X_train)[:,1])\n",
    "print(acc)\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8525540158701921\n",
      "0.912425\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(y_val, model.predict_proba(X_val)[:,1]))\n",
    "print(model.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cuantos parámetros aprendio el modelo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 200)\n",
      "(1,)\n"
     ]
    }
   ],
   "source": [
    "print(model.coef_.shape)\n",
    "print(model.intercept_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo aprendió 201 parámetros: 1 por cada feature (200) + Intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=10000)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(solver='lbfgs', max_iter = 10000)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.913925\n",
      "0.8627138133096955\n"
     ]
    }
   ],
   "source": [
    "print(model.score(X_val, y_val))\n",
    "print(roc_auc_score(y_val, model.predict_proba(X_val)[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = X_train.mean(axis=0)\n",
    "stds = X_train.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_normalized = (X_train - means)/stds\n",
    "X_val_normalized = (X_val - means)/stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.57581888, -1.27213281,  0.45287052, ..., -0.37754551,\n",
       "        -1.02664168,  0.21435054],\n",
       "       [ 0.2712627 , -0.62084311,  1.19211864, ..., -0.13305653,\n",
       "         0.82532811,  0.50563783],\n",
       "       [-0.67983317, -0.27493645,  0.51820418, ..., -0.69861357,\n",
       "        -0.38163924,  0.35676851],\n",
       "       ...,\n",
       "       [-0.36992848,  0.29836631, -1.02369299, ...,  1.02268001,\n",
       "         1.20524149,  0.97469155],\n",
       "       [-0.85496666, -0.23515324,  0.40515876, ...,  0.58630947,\n",
       "        -1.17760394,  1.52298016],\n",
       "       [ 0.34159241, -0.12772376, -0.69278026, ..., -1.1042874 ,\n",
       "         0.05643364,  0.39886503]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.57581888, -1.27213281,  0.45287052, ..., -0.37754551,\n",
       "        -1.02664168,  0.21435054],\n",
       "       [ 0.2712627 , -0.62084311,  1.19211864, ..., -0.13305653,\n",
       "         0.82532811,  0.50563783],\n",
       "       [-0.67983317, -0.27493645,  0.51820418, ..., -0.69861357,\n",
       "        -0.38163924,  0.35676851],\n",
       "       ...,\n",
       "       [-0.36992848,  0.29836631, -1.02369299, ...,  1.02268001,\n",
       "         1.20524149,  0.97469155],\n",
       "       [-0.85496666, -0.23515324,  0.40515876, ...,  0.58630947,\n",
       "        -1.17760394,  1.52298016],\n",
       "       [ 0.34159241, -0.12772376, -0.69278026, ..., -1.1042874 ,\n",
       "         0.05643364,  0.39886503]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.88 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2 = LogisticRegression(solver='lbfgs')\n",
    "%time model_2.fit(X_train_normalized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.91440625\n",
      "0.8606427353156717\n"
     ]
    }
   ],
   "source": [
    "print(model_2.score(X_train_normalized, y_train))\n",
    "print(roc_auc_score(y_train, model_2.predict_proba(X_train_normalized)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.914525\n",
      "0.8629075884886785\n"
     ]
    }
   ],
   "source": [
    "print(model_2.score(X_val_normalized, y_val))\n",
    "print(roc_auc_score(y_val, model_2.predict_proba(X_val_normalized)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 81, 139,   6,  12,  53, 110,  76,  99, 146, 174,  26,  21,  22,\n",
       "        80, 190, 166, 165, 198,  13,  34, 169,  44,   2, 148,   0,  40,\n",
       "       133, 179, 170,  78,  94,   1, 184, 109,  33, 115,  92,  67, 149,\n",
       "       108, 191, 122, 173, 154,  18,  86, 192, 118, 107, 121, 147,  95,\n",
       "         9,  75,  35, 164, 177, 197, 172,  36, 127,  89, 123, 155,  91,\n",
       "       188,  56,  87,  71,  48,   5,  93, 162, 106, 157, 130, 141, 145,\n",
       "        24, 151,  32, 167, 163, 150, 186, 119,  49,  31, 180,  23, 111,\n",
       "       195,  90, 131, 125, 137, 114, 199,  43, 116, 135,  52,  58, 128,\n",
       "        70, 104, 175, 112, 132, 105,  11, 196,  85,  82, 194,  51,  28,\n",
       "       142,  83,  66, 134, 144, 138,  74,  45, 156,  77,  55,  97, 140,\n",
       "        20,  54, 193,  57,  88, 178,   8, 102, 113,  62,  15, 143, 159,\n",
       "       187, 181, 171,  63,  72,  64,  50,  59, 120, 168, 182, 101,  25,\n",
       "        68,   3,  65, 152,   4,  84,  37,  42, 176,  61, 129,  19, 189,\n",
       "        69,  47,  60,  16,  27,  29,  79,  73, 158,  96, 160,  46, 124,\n",
       "        98,  14, 153, 126,  39, 136, 183, 117,  41, 103, 100, 161,  10,\n",
       "         7, 185,  38,  17,  30], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ordenamos el valor absoluto de los parámetros de mayor a menor\n",
    "# Coeficientes ordenados en función de su de mayor importancia\n",
    "np.argsort(np.abs(model_2.coef_))[0][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  7,   9,  10,  12,  13,  14,  17,  20,  21,  23,  27,  28,  30,\n",
       "        31,  33,  34,  36,  38,  39,  41,  42,  43,  44,  45,  50,  54,\n",
       "        56,  57,  58,  59,  63,  64,  72,  73,  75,  76,  77,  80,  81,\n",
       "        83,  85,  86,  87,  88,  92,  93,  98, 101, 102, 103, 104, 107,\n",
       "       108, 109, 113, 114, 115, 116, 120, 121, 122, 123, 127, 129, 131,\n",
       "       132, 136, 139, 141, 142, 143, 146, 148, 149, 150, 152, 153, 154,\n",
       "       156, 158, 160, 165, 166, 169, 172, 174, 177, 178, 182, 183, 185,\n",
       "       186, 188, 192, 193, 194, 197, 198], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parámetros menores a cero\n",
    "negative_indexes = np.where(model.coef_<0)[1]\n",
    "negative_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   3,   4,   5,   6,   8,  11,  15,  16,  18,  19,\n",
       "        22,  24,  25,  26,  29,  32,  35,  37,  40,  46,  47,  48,  49,\n",
       "        51,  52,  53,  55,  60,  61,  62,  65,  66,  67,  68,  69,  70,\n",
       "        71,  74,  78,  79,  82,  84,  89,  90,  91,  94,  95,  96,  97,\n",
       "        99, 100, 105, 106, 110, 111, 112, 117, 118, 119, 124, 125, 126,\n",
       "       128, 130, 133, 134, 135, 137, 138, 140, 144, 145, 147, 151, 155,\n",
       "       157, 159, 161, 162, 163, 164, 167, 168, 170, 171, 173, 175, 176,\n",
       "       179, 180, 181, 184, 187, 189, 190, 191, 195, 196, 199], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parámetros mayores a cero\n",
    "positive_indexes = np.where(model.coef_>0)[1]\n",
    "positive_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9607843137254902"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(negative_indexes)/len(positive_indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notar que hay algunos parámetros mayores a cero y otros menores a cero. Como contribuyen en función de su signo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 81, 139,  12,  76, 146, 174,  21,  80, 166, 165, 198,  13,  34,\n",
       "       169,  44, 148, 109,  33, 115,  92, 149, 108, 122, 154,  86, 192,\n",
       "       107, 121,   9,  75, 177, 197, 172,  36, 127, 123, 188,  56,  87,\n",
       "        93, 141, 150, 186,  31,  23, 131, 114,  43, 116,  58, 104, 132,\n",
       "        85, 194,  28, 142,  83,  45, 156,  77,  20,  54, 193,  57,  88,\n",
       "       178, 102, 113, 143,  63,  72,  64,  50,  59, 120, 182, 101,  68,\n",
       "       152,  42, 129,  27,  73, 158, 160,  98,  14, 153,  39, 136, 183,\n",
       "        41, 103,  10,   7, 185,  38,  17,  30, 161, 100, 117, 126, 124,\n",
       "        46,  96,  79,  29,  16,  60,  47,  69, 189,  19,  61, 176,  37,\n",
       "        84,   4,  65,   3,  25, 168, 171, 181, 187, 159,  15,  62,   8,\n",
       "       140,  97,  55,  74, 138, 144, 134,  66,  51,  82, 196,  11, 105,\n",
       "       112, 175,  70, 128,  52, 135, 199, 137, 125,  90, 195, 111, 180,\n",
       "        49, 119, 163, 167,  32, 151,  24, 145, 130, 157, 106, 162,   5,\n",
       "        48,  71,  91, 155,  89, 164,  35,  95, 147, 118,  18, 173, 191,\n",
       "        67, 184,   1,  94,  78, 170, 179, 133,  40,   0,   2, 190,  22,\n",
       "        26,  99, 110,  53,   6], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ordenados de menor a mayor\n",
    "np.argsort(model_2.coef_)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  6,  53, 110,  99,  26,  22, 190,   2,   0,  40, 133, 179, 170,\n",
       "        78,  94,   1, 184,  67, 191, 173,  18, 118, 147,  95,  35, 164,\n",
       "        89, 155,  91,  71,  48,   5, 162, 106, 157, 130, 145,  24, 151,\n",
       "        32, 167, 163, 119,  49, 180, 111, 195,  90, 125, 137, 199, 135,\n",
       "        52, 128,  70, 175, 112, 105,  11, 196,  82,  51,  66, 134, 144,\n",
       "       138,  74,  55,  97, 140,   8,  62,  15, 159, 187, 181, 171, 168,\n",
       "        25,   3,  65,   4,  84,  37, 176,  61,  19, 189,  69,  47,  60,\n",
       "        16,  29,  79,  96,  46, 124, 126, 117, 100, 161,  30,  17,  38,\n",
       "       185,   7,  10, 103,  41, 183, 136,  39, 153,  14,  98, 160, 158,\n",
       "        73,  27, 129,  42, 152,  68, 101, 182, 120,  59,  50,  64,  72,\n",
       "        63, 143, 113, 102, 178,  88,  57, 193,  54,  20,  77, 156,  45,\n",
       "        83, 142,  28, 194,  85, 132, 104,  58, 116,  43, 114, 131,  23,\n",
       "        31, 186, 150, 141,  93,  87,  56, 188, 123, 127,  36, 172, 197,\n",
       "       177,  75,   9, 121, 107, 192,  86, 154, 122, 108, 149,  92, 115,\n",
       "        33, 109, 148,  44, 169,  34,  13, 198, 165, 166,  80,  21, 174,\n",
       "       146,  76,  12, 139,  81], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ordenados de mayor a menor\n",
    "np.argsort(model_2.coef_)[0][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos correlación de cada variable con la salida\n",
    "correlations = []\n",
    "for i in range(200):\n",
    "    correlations.append(np.corrcoef(y_train, X_train_normalized[:,i])[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 81, 139,  12, 110,   6,  26,  53, 146, 174,  76,  99,  80, 166,\n",
       "        22, 165,  21, 190, 148,   2,  13,  34, 133,   0, 198, 169, 109,\n",
       "       179,  44,  40,   1, 115, 149, 170, 184,  78,  94,  92, 108,  67,\n",
       "       191,  33,  18, 154, 173,  86, 122, 192, 147, 118,   9, 121,  75,\n",
       "        95, 164, 123,  35,  91,  36, 172, 127, 107, 155,  89, 177, 197,\n",
       "        56,  93, 188,  87,  71, 162,  48, 157, 106, 141, 145,   5,  32,\n",
       "       163, 131, 167, 186, 119,  49,  24, 151, 130,  90, 111, 135, 180,\n",
       "       125,  43,  51, 114, 195, 199,  52,  23, 150,  31, 116,  85,  70,\n",
       "       137, 105, 128, 104,  58, 112, 196, 132,  11,  28, 175,  66,  82,\n",
       "       194, 156,  83, 142,  45, 144,  88,  74, 178, 138,  77,   8,  97,\n",
       "       134,  20,  55, 193,  54,  15, 102,  57, 159, 140, 171,  62, 113,\n",
       "       187,  63, 143,  64,  25, 181,  50, 120, 168,  59,   3,  72,  65,\n",
       "        68,  84, 101,  19,   4,  37,  61,  69, 189, 152, 182,  42,  16,\n",
       "       129, 176,  47,  79, 153,  14, 183,  46, 160,  73,  60,  98, 158,\n",
       "       124,  27, 100,  96,  29,  39,  10, 117, 136,   7,  41, 103,  38,\n",
       "       161, 185,  30, 126,  17], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(np.abs(correlations))[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identificando los coeficientes de correlación entre Features y Outputs, se puede identificar qué parámetros del modelo se correlacionan más con la predicción."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregamos 200 columnas con el cuadrado de cada columna normaliado a train\n",
    "X_train_sq = X_train_normalized**2\n",
    "means_sq = X_train_sq.mean(axis=0)\n",
    "stds_sq = X_train_sq.std(axis=0)\n",
    "X_train_FE = np.append(X_train_normalized, (X_train_sq - means_sq)/stds_sq, axis=1)\n",
    "\n",
    "# Agregamos el cuadrado a validación normalizando con la media y std obtenida en train\n",
    "X_val_sq = X_val_normalized**2\n",
    "X_val_FE = np.append(X_val_normalized, (X_val_normalized**2-means_sq)/stds_sq, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.52 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3 = LogisticRegression(solver='lbfgs')\n",
    "%time model_3.fit(X_train_FE, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9221\n",
      "0.8927208962331821\n"
     ]
    }
   ],
   "source": [
    "print(model_3.score(X_val_FE, y_val))\n",
    "print(roc_auc_score(y_val, model_3.predict_proba(X_val_FE)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "401\n"
     ]
    }
   ],
   "source": [
    "# Cantidad de parámetros aprendidos por el modelo:\n",
    "print(len(model_3.coef_[0]) + len(model_3.intercept_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([139,  81,   6,  53,  12,  21,  76, 174, 110,  34, 146,  26, 169,\n",
       "        99, 165, 281,  22, 166, 190,  78,  33,  40,  13, 170, 149,  80,\n",
       "       148, 184,  94, 109, 133, 192,  92, 122, 115,  67, 121, 198,   0,\n",
       "         1, 173, 179,   2, 212,  18, 118, 108, 253, 398, 107, 191, 172,\n",
       "       177,  44, 154, 310, 164,  35, 197, 226, 188,  36, 339, 299,  75,\n",
       "       147, 244,   9, 280,  86,  87, 366,  95,  89,  48, 390, 127,  91,\n",
       "       222, 309,  71, 346, 155, 202,   5, 323, 374, 379,  56, 145, 106,\n",
       "       162, 123, 206, 221,  32, 186, 141, 200, 150, 348, 151,  31, 365,\n",
       "       199,  49, 130, 240,  23, 278, 167, 157,  24, 333,  90, 276,  93,\n",
       "       111, 119, 354, 137, 364, 195, 286, 363, 128, 112, 180, 380,  52,\n",
       "       104, 114,  58, 131,  70, 355, 116, 125, 135, 295, 370, 233, 391,\n",
       "       292, 201,  43, 275, 175, 196, 293, 357, 388, 294,  85, 163, 213,\n",
       "       347,  82, 308, 142, 132,  28, 105,  11, 319, 234, 194, 291,  74,\n",
       "       205,  97,  77, 140, 315,  45, 322,  20, 369,  55, 267, 256, 287,\n",
       "       156,  66, 289, 251, 144,  51,  54, 306, 332,  83, 377, 397, 321,\n",
       "       138, 134, 384, 330, 243, 218, 335,  57, 362, 341,   8,  88, 232,\n",
       "       345, 102, 314, 113, 178, 193, 372, 159, 307, 325, 209, 250, 331,\n",
       "       235, 373, 395, 367, 236, 311, 249, 396, 143, 288, 258, 252, 269,\n",
       "       187,  62, 318,  59, 327, 271,  64,  15, 368, 171, 349,  72, 312,\n",
       "       260,  63, 120, 350, 334, 211, 101,  50, 371, 375, 328, 168, 393,\n",
       "       394, 268,   4, 352, 262, 338, 351,  65,  84, 344, 181, 176, 228,\n",
       "       386, 283, 272, 343, 216, 337, 387,  42, 152, 282, 215, 189, 182,\n",
       "         3, 270, 248,  37, 219,  25, 305,  68,  19, 353, 290, 129, 279,\n",
       "       381, 285,  61, 378, 302, 298, 297, 263, 336, 203, 266, 246, 223,\n",
       "       356, 277, 316, 239, 342, 241,  69, 208, 204,  29, 304, 392,  47,\n",
       "        96, 301, 225, 383, 399, 313, 255, 153, 259, 324, 326, 160, 265,\n",
       "       238, 245, 158, 261, 224,  16, 136,  39, 126,  41,  27, 376, 329,\n",
       "        73,  60, 242, 317, 227, 124,  46,  79, 360,  14, 183, 257,  98,\n",
       "       229, 303, 237, 296, 264, 274, 103, 273, 359, 320, 210, 361, 300,\n",
       "       185, 389, 385, 247, 214, 284, 161, 217, 358, 207, 100, 340, 220,\n",
       "        38, 382, 230,  17, 231,   7,  10, 117, 254,  30])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Coeficientes ordenados en función de su de mayor importancia\n",
    "np.argsort(np.abs(model_3.coef_))[0][::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Independecia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [00:20<00:00,  9.63it/s]\n"
     ]
    }
   ],
   "source": [
    "accs = []\n",
    "aucs = []\n",
    "val_predictions = np.zeros((len(X_val_normalized), 200))\n",
    "train_predictions = np.zeros((len(X_train_normalized), 200))\n",
    "for i in tqdm.tqdm(range(200)):\n",
    "    model_ind = LogisticRegression(solver='lbfgs')\n",
    "    X_one_train = X_train_normalized[:,i].reshape(-1,1)\n",
    "    # X_one_train = np.array([X_train_normalized[:,i], X_train_normalized[:,i]**2]).T\n",
    "    model_ind.fit(X_one_train, y_train)\n",
    "    X_one_val = X_val_normalized[:,i].reshape(-1,1)\n",
    "    # X_one_val = np.array([X_val_normalized[:,i], X_val_normalized[:,i]**2]).T\n",
    "    train_predictions[:, i] = model_ind.predict_proba(X_one_train)[:,1]\n",
    "    val_predictions[:, i] = model_ind.predict_proba(X_one_val)[:,1]\n",
    "    acc = model_ind.score(X_one_val, y_val)\n",
    "    auc = roc_auc_score(y_val, val_predictions[:, i])\n",
    "    accs.append(acc)\n",
    "    aucs.append(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8692585548756987"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_train, train_predictions.sum(axis=1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8729094090424484"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_val, val_predictions.sum(axis=1)) \n",
    "# 0.8729094090424484"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:diplo]",
   "language": "python",
   "name": "conda-env-diplo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
